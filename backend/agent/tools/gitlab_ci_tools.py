"""
GitLab CI/CD Tools for NAVI
Provides tools for generating GitLab CI/CD pipelines and configurations.
"""

import os
import json
from typing import Any, Dict, List

from backend.services.connector_base import ToolResult


# ============================================================================
# GitLab CI/CD Pipeline Generation
# ============================================================================

async def generate_gitlab_ci(context: Dict[str, Any]) -> ToolResult:
    """
    Generate a complete GitLab CI/CD pipeline configuration.

    Args (from context):
        workspace_path: Path to the project
        stages: List of stages to include (default: lint, test, build, security, deploy)
        include_security: Whether to include security scanning stages
        environments: List of deployment environments
        docker_enabled: Whether to use Docker-in-Docker
        cache_enabled: Whether to enable caching
    """
    workspace_path = context.get("workspace_path", ".")
    stages = context.get("stages", ["lint", "test", "build", "security", "deploy"])
    include_security = context.get("include_security", True)
    environments = context.get("environments", ["staging", "production"])
    docker_enabled = context.get("docker_enabled", True)
    cache_enabled = context.get("cache_enabled", True)

    # Detect project type
    project_info = await _detect_project_type(workspace_path)
    project_type = project_info["type"]
    package_manager = project_info.get("package_manager", "npm")

    # Build the pipeline configuration
    pipeline = {
        "stages": stages,
        "variables": _generate_variables(project_type, docker_enabled),
    }

    # Add default settings
    pipeline["default"] = {
        "image": _get_default_image(project_type),
        "retry": {
            "max": 2,
            "when": ["runner_system_failure", "stuck_or_timeout_failure"]
        }
    }

    # Add cache configuration
    if cache_enabled:
        pipeline["cache"] = _generate_cache_config(project_type, package_manager)

    # Add before_script for dependency installation
    pipeline["before_script"] = _generate_before_script(project_type, package_manager)

    # Generate jobs for each stage
    jobs = {}

    # Lint stage
    if "lint" in stages:
        jobs.update(_generate_lint_jobs(project_type, package_manager))

    # Test stage
    if "test" in stages:
        jobs.update(_generate_test_jobs(project_type, package_manager))

    # Build stage
    if "build" in stages:
        jobs.update(_generate_build_jobs(project_type, package_manager, docker_enabled))

    # Security stage
    if "security" in stages and include_security:
        jobs.update(_generate_security_jobs(project_type))

    # Deploy stage
    if "deploy" in stages:
        jobs.update(_generate_deploy_jobs(project_type, environments))

    # Merge jobs into pipeline
    pipeline.update(jobs)

    # Convert to YAML
    yaml_content = _dict_to_gitlab_yaml(pipeline)

    # Write the file
    output_path = os.path.join(workspace_path, ".gitlab-ci.yml")

    output = f"""# GitLab CI/CD Pipeline Configuration
# Generated by NAVI - Autonomous Engineering Platform
# Project Type: {project_type}

## Pipeline Overview
- **Stages**: {', '.join(stages)}
- **Environments**: {', '.join(environments)}
- **Security Scanning**: {'Enabled' if include_security else 'Disabled'}
- **Docker Support**: {'Enabled' if docker_enabled else 'Disabled'}
- **Caching**: {'Enabled' if cache_enabled else 'Disabled'}

## Generated Configuration

```yaml
{yaml_content}
```

## File Location
- Path: `{output_path}`

## Jobs Created
{_format_jobs_summary(jobs)}

## Next Steps
1. Review the generated `.gitlab-ci.yml` file
2. Configure CI/CD variables in GitLab:
   - `DOCKER_REGISTRY` - Your Docker registry URL
   - `DOCKER_USER` / `DOCKER_PASSWORD` - Registry credentials
   - `DEPLOY_TOKEN` - Deployment authentication
   - `SONAR_TOKEN` - SonarQube token (if using)
3. Set up environments in GitLab with appropriate protection rules
4. Configure runners with the `docker` executor
"""

    return ToolResult(output=output, sources=[output_path])


async def add_gitlab_ci_stage(context: Dict[str, Any]) -> ToolResult:
    """
    Add a new stage or job to an existing GitLab CI pipeline.

    Args (from context):
        workspace_path: Path to the project
        stage_name: Name of the stage to add
        job_config: Configuration for the job
        position: Position to insert the stage (before/after existing stage)
    """
    workspace_path = context.get("workspace_path", ".")
    stage_name = context.get("stage_name", "")
    job_config = context.get("job_config", {})
    job_name = context.get("job_name", stage_name)

    if not stage_name:
        return ToolResult(output="Error: stage_name is required", sources=[])

    gitlab_ci_path = os.path.join(workspace_path, ".gitlab-ci.yml")

    # Generate job YAML
    job_yaml = _generate_custom_job(job_name, stage_name, job_config)

    output = f"""# Add Stage to GitLab CI Pipeline

## New Stage: `{stage_name}`
## Job Name: `{job_name}`

### Job Configuration
```yaml
{job_yaml}
```

### Instructions

1. **Add to stages list** (if new stage):
```yaml
stages:
  - lint
  - test
  - {stage_name}  # Add this line
  - build
  - deploy
```

2. **Add the job definition** at the end of your `.gitlab-ci.yml`:
```yaml
{job_yaml}
```

### Common Stage Types

| Stage | Purpose | Example Jobs |
|-------|---------|--------------|
| lint | Code quality | eslint, prettier, pylint |
| test | Unit/integration tests | jest, pytest, go test |
| build | Create artifacts | docker build, npm build |
| security | Vulnerability scanning | SAST, DAST, dependency scan |
| deploy | Deploy to environments | kubectl, helm, terraform |
| notify | Send notifications | Slack, email |
| cleanup | Remove temporary resources | Docker cleanup, temp files |
"""

    return ToolResult(output=output, sources=[gitlab_ci_path])


async def setup_gitlab_runners(context: Dict[str, Any]) -> ToolResult:
    """
    Generate GitLab Runner configuration and setup instructions.

    Args (from context):
        runner_type: Type of runner (docker, shell, kubernetes)
        concurrent: Number of concurrent jobs
        tags: List of runner tags
        docker_image: Default Docker image for jobs
    """
    runner_type = context.get("runner_type", "docker")
    concurrent = context.get("concurrent", 4)
    tags = context.get("tags", ["docker", "linux"])
    docker_image = context.get("docker_image", "docker:24.0.5")

    # Generate runner configuration
    if runner_type == "docker":
        config = _generate_docker_runner_config(concurrent, tags, docker_image)
    elif runner_type == "kubernetes":
        config = _generate_k8s_runner_config(concurrent, tags)
    else:
        config = _generate_shell_runner_config(concurrent, tags)

    output = f"""# GitLab Runner Setup

## Runner Type: `{runner_type}`
## Concurrent Jobs: `{concurrent}`
## Tags: `{', '.join(tags)}`

### Configuration File (`config.toml`)

```toml
{config}
```

### Installation Instructions

#### Option 1: Docker Installation
```bash
# Run GitLab Runner in Docker
docker run -d --name gitlab-runner --restart always \\
  -v /srv/gitlab-runner/config:/etc/gitlab-runner \\
  -v /var/run/docker.sock:/var/run/docker.sock \\
  gitlab/gitlab-runner:latest

# Register the runner
docker exec -it gitlab-runner gitlab-runner register \\
  --url "https://gitlab.com/" \\
  --registration-token "YOUR_TOKEN" \\
  --executor "{runner_type}" \\
  --description "NAVI Runner" \\
  --tag-list "{','.join(tags)}" \\
  --run-untagged="true" \\
  --locked="false"
```

#### Option 2: Binary Installation
```bash
# Linux (amd64)
curl -L --output /usr/local/bin/gitlab-runner \\
  "https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64"
chmod +x /usr/local/bin/gitlab-runner

# Install and start service
gitlab-runner install
gitlab-runner start

# Register runner
gitlab-runner register
```

#### Option 3: Kubernetes Helm Chart
```bash
helm repo add gitlab https://charts.gitlab.io
helm repo update
helm install gitlab-runner gitlab/gitlab-runner \\
  --set gitlabUrl=https://gitlab.com/ \\
  --set runnerRegistrationToken=YOUR_TOKEN \\
  --set runners.privileged=true
```

### Verification
```bash
# Check runner status
gitlab-runner verify

# List registered runners
gitlab-runner list

# Run a test job
gitlab-runner exec docker test
```

### Best Practices
1. Use dedicated runners for production deployments
2. Tag runners appropriately for job routing
3. Set up autoscaling for variable workloads
4. Configure proper resource limits
5. Enable metrics for monitoring
"""

    return ToolResult(output=output, sources=[])


async def generate_gitlab_cd(context: Dict[str, Any]) -> ToolResult:
    """
    Generate GitLab CD (Continuous Deployment) configuration with environments.

    Args (from context):
        workspace_path: Path to the project
        environments: List of environment configs
        deployment_strategy: Strategy (rolling, blue_green, canary)
        auto_deploy: Enable auto-deployment for certain environments
    """
    workspace_path = context.get("workspace_path", ".")
    environments = context.get("environments", [
        {"name": "development", "auto_deploy": True},
        {"name": "staging", "auto_deploy": True, "requires_approval": False},
        {"name": "production", "auto_deploy": False, "requires_approval": True}
    ])
    deployment_strategy = context.get("deployment_strategy", "rolling")

    # Detect project type for deployment method
    project_info = await _detect_project_type(workspace_path)

    # Generate CD configuration
    cd_config = _generate_cd_config(environments, deployment_strategy, project_info)

    yaml_content = _dict_to_gitlab_yaml(cd_config)

    output = f"""# GitLab CD (Continuous Deployment) Configuration

## Deployment Strategy: `{deployment_strategy}`
## Environments: {', '.join([e['name'] for e in environments])}

### CD Pipeline Configuration

```yaml
{yaml_content}
```

### Environment Setup in GitLab

For each environment, configure in **Settings > CI/CD > Environments**:

| Environment | Auto Deploy | Approval Required | Branch Pattern |
|-------------|-------------|-------------------|----------------|
{_format_env_table(environments)}

### Deployment Strategies

#### Rolling Deployment (Current)
- Gradually replaces old instances with new ones
- Zero downtime
- Automatic rollback on failure

#### Blue-Green Deployment
```yaml
.blue_green_deploy:
  script:
    - kubectl apply -f k8s/green/
    - kubectl wait --for=condition=ready pod -l version=green
    - kubectl patch service $SERVICE -p '{{"spec":{{"selector":{{"version":"green"}}}}}}'
    - kubectl delete -f k8s/blue/
```

#### Canary Deployment
```yaml
.canary_deploy:
  script:
    - kubectl apply -f k8s/canary/
    - sleep 300  # Monitor for 5 minutes
    - |
      if check_metrics_healthy; then
        kubectl scale deployment canary --replicas=0
        kubectl scale deployment production --replicas=$REPLICAS
      else
        kubectl rollout undo deployment/canary
        exit 1
      fi
```

### Environment Variables

Configure these in **Settings > CI/CD > Variables**:

| Variable | Environment | Description |
|----------|-------------|-------------|
| `KUBE_CONFIG` | All | Kubernetes configuration |
| `DEPLOY_TOKEN` | All | Deployment authentication |
| `ROLLBAR_TOKEN` | production | Error tracking token |
| `SLACK_WEBHOOK` | All | Notification webhook |

### Approval Workflows

For production deployments with approval:
1. Go to **Settings > CI/CD > General pipelines**
2. Enable "Protected environments"
3. Configure approvers for production environment
"""

    return ToolResult(output=output, sources=[])


async def generate_gitlab_templates(context: Dict[str, Any]) -> ToolResult:
    """
    Generate reusable GitLab CI/CD templates.

    Args (from context):
        template_type: Type of template (docker, node, python, terraform)
        output_dir: Directory to output templates
    """
    template_type = context.get("template_type", "all")
    output_dir = context.get("output_dir", ".gitlab/ci")
    workspace_path = context.get("workspace_path", ".")

    templates = {}

    if template_type in ["all", "docker"]:
        templates["docker.yml"] = _generate_docker_template()

    if template_type in ["all", "node"]:
        templates["node.yml"] = _generate_node_template()

    if template_type in ["all", "python"]:
        templates["python.yml"] = _generate_python_template()

    if template_type in ["all", "terraform"]:
        templates["terraform.yml"] = _generate_terraform_template()

    if template_type in ["all", "security"]:
        templates["security.yml"] = _generate_security_template()

    output_path = os.path.join(workspace_path, output_dir)

    templates_content = "\n\n---\n\n".join([
        f"# {name}\n```yaml\n{content}\n```"
        for name, content in templates.items()
    ])

    output = f"""# GitLab CI/CD Templates

## Output Directory: `{output_path}`

### Generated Templates

{templates_content}

### Usage in `.gitlab-ci.yml`

```yaml
include:
  - local: '{output_dir}/docker.yml'
  - local: '{output_dir}/node.yml'
  - local: '{output_dir}/security.yml'

stages:
  - lint
  - test
  - build
  - security
  - deploy

# Extend templates
lint:
  extends: .node:lint

test:
  extends: .node:test

build:
  extends: .docker:build

deploy:
  extends: .docker:deploy
```

### Template Inheritance

Templates use GitLab's `extends` keyword for DRY configuration:

```yaml
# In your job
my_job:
  extends: .template_name
  variables:
    CUSTOM_VAR: "value"  # Override template variables
```
"""

    return ToolResult(output=output, sources=[output_path])


# ============================================================================
# Helper Functions
# ============================================================================

async def _detect_project_type(workspace_path: str) -> Dict[str, Any]:
    """Detect project type from workspace files."""
    project_info = {"type": "unknown", "package_manager": "npm"}

    # Check for Node.js
    if os.path.exists(os.path.join(workspace_path, "package.json")):
        project_info["type"] = "node"
        if os.path.exists(os.path.join(workspace_path, "yarn.lock")):
            project_info["package_manager"] = "yarn"
        elif os.path.exists(os.path.join(workspace_path, "pnpm-lock.yaml")):
            project_info["package_manager"] = "pnpm"
        else:
            project_info["package_manager"] = "npm"

        # Check for specific frameworks
        try:
            with open(os.path.join(workspace_path, "package.json"), "r") as f:
                pkg = json.load(f)
                deps = {**pkg.get("dependencies", {}), **pkg.get("devDependencies", {})}
                if "next" in deps:
                    project_info["type"] = "nextjs"
                elif "nuxt" in deps:
                    project_info["type"] = "nuxt"
                elif "@nestjs/core" in deps:
                    project_info["type"] = "nestjs"
                elif "express" in deps:
                    project_info["type"] = "express"
                elif "react" in deps:
                    project_info["type"] = "react"
                elif "vue" in deps:
                    project_info["type"] = "vue"
        except:
            pass

    # Check for Python
    elif os.path.exists(os.path.join(workspace_path, "pyproject.toml")):
        project_info["type"] = "python"
        project_info["package_manager"] = "poetry"
    elif os.path.exists(os.path.join(workspace_path, "requirements.txt")):
        project_info["type"] = "python"
        project_info["package_manager"] = "pip"

    # Check for Go
    elif os.path.exists(os.path.join(workspace_path, "go.mod")):
        project_info["type"] = "go"
        project_info["package_manager"] = "go"

    # Check for Rust
    elif os.path.exists(os.path.join(workspace_path, "Cargo.toml")):
        project_info["type"] = "rust"
        project_info["package_manager"] = "cargo"

    # Check for Java
    elif os.path.exists(os.path.join(workspace_path, "pom.xml")):
        project_info["type"] = "java"
        project_info["package_manager"] = "maven"
    elif os.path.exists(os.path.join(workspace_path, "build.gradle")):
        project_info["type"] = "java"
        project_info["package_manager"] = "gradle"

    return project_info


def _generate_variables(project_type: str, docker_enabled: bool) -> Dict[str, str]:
    """Generate pipeline variables."""
    variables = {
        "GIT_DEPTH": "10",
        "GIT_STRATEGY": "fetch",
    }

    if docker_enabled:
        variables.update({
            "DOCKER_DRIVER": "overlay2",
            "DOCKER_TLS_CERTDIR": "/certs",
            "DOCKER_HOST": "tcp://docker:2376",
            "DOCKER_TLS_VERIFY": "1",
            "DOCKER_CERT_PATH": "/certs/client",
        })

    if project_type in ["node", "nextjs", "react", "vue", "express", "nestjs"]:
        variables["NODE_ENV"] = "test"
    elif project_type == "python":
        variables["PYTHONDONTWRITEBYTECODE"] = "1"
        variables["PYTHONUNBUFFERED"] = "1"

    return variables


def _get_default_image(project_type: str) -> str:
    """Get default Docker image for project type."""
    images = {
        "node": "node:20-alpine",
        "nextjs": "node:20-alpine",
        "react": "node:20-alpine",
        "vue": "node:20-alpine",
        "express": "node:20-alpine",
        "nestjs": "node:20-alpine",
        "python": "python:3.11-slim",
        "go": "golang:1.21-alpine",
        "rust": "rust:1.74-slim",
        "java": "maven:3.9-eclipse-temurin-21",
    }
    return images.get(project_type, "alpine:latest")


def _generate_cache_config(project_type: str, package_manager: str) -> Dict[str, Any]:
    """Generate cache configuration."""
    cache_paths = {
        "npm": ["node_modules/", ".npm/"],
        "yarn": ["node_modules/", ".yarn/cache/"],
        "pnpm": ["node_modules/", ".pnpm-store/"],
        "pip": [".pip-cache/", ".venv/"],
        "poetry": [".venv/", ".cache/pypoetry/"],
        "go": ["/go/pkg/mod/"],
        "cargo": ["/usr/local/cargo/registry/", "target/"],
    }

    key_files = {
        "npm": "package-lock.json",
        "yarn": "yarn.lock",
        "pnpm": "pnpm-lock.yaml",
        "pip": "requirements.txt",
        "poetry": "poetry.lock",
        "go": "go.sum",
        "cargo": "Cargo.lock",
    }

    return {
        "key": f"$CI_COMMIT_REF_SLUG-{key_files.get(package_manager, 'deps')}",
        "paths": cache_paths.get(package_manager, []),
        "policy": "pull-push",
    }


def _generate_before_script(project_type: str, package_manager: str) -> List[str]:
    """Generate before_script commands."""
    scripts = {
        "npm": ["npm ci --prefer-offline"],
        "yarn": ["yarn install --frozen-lockfile"],
        "pnpm": ["pnpm install --frozen-lockfile"],
        "pip": ["pip install -r requirements.txt"],
        "poetry": ["poetry install --no-interaction"],
        "go": ["go mod download"],
        "cargo": ["cargo fetch"],
    }
    return scripts.get(package_manager, [])


def _generate_lint_jobs(project_type: str, package_manager: str) -> Dict[str, Any]:
    """Generate lint stage jobs."""
    jobs = {}

    if project_type in ["node", "nextjs", "react", "vue", "express", "nestjs"]:
        run_cmd = "npm run" if package_manager == "npm" else f"{package_manager} run"
        jobs["lint"] = {
            "stage": "lint",
            "script": [
                f"{run_cmd} lint || true",
                f"{run_cmd} format:check || true",
            ],
            "allow_failure": True,
        }
        jobs["typecheck"] = {
            "stage": "lint",
            "script": [f"{run_cmd} typecheck || {run_cmd} tsc --noEmit || true"],
            "allow_failure": True,
        }
    elif project_type == "python":
        jobs["lint"] = {
            "stage": "lint",
            "script": [
                "pip install ruff black mypy",
                "ruff check . || true",
                "black --check . || true",
                "mypy . || true",
            ],
            "allow_failure": True,
        }
    elif project_type == "go":
        jobs["lint"] = {
            "stage": "lint",
            "script": [
                "go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest",
                "golangci-lint run || true",
            ],
            "allow_failure": True,
        }

    return jobs


def _generate_test_jobs(project_type: str, package_manager: str) -> Dict[str, Any]:
    """Generate test stage jobs."""
    jobs = {}

    if project_type in ["node", "nextjs", "react", "vue", "express", "nestjs"]:
        run_cmd = "npm run" if package_manager == "npm" else f"{package_manager} run"
        jobs["test:unit"] = {
            "stage": "test",
            "script": [f"{run_cmd} test -- --coverage"],
            "coverage": "/All files[^|]*\\|[^|]*\\s+([\\d\\.]+)/",
            "artifacts": {
                "reports": {
                    "junit": "junit.xml",
                    "coverage_report": {
                        "coverage_format": "cobertura",
                        "path": "coverage/cobertura-coverage.xml",
                    }
                },
                "paths": ["coverage/"],
                "expire_in": "1 week",
            },
        }
    elif project_type == "python":
        jobs["test:unit"] = {
            "stage": "test",
            "script": [
                "pip install pytest pytest-cov pytest-asyncio",
                "pytest --cov=. --cov-report=xml --cov-report=html --junitxml=junit.xml",
            ],
            "coverage": "/TOTAL.*\\s+(\\d+%)$/",
            "artifacts": {
                "reports": {
                    "junit": "junit.xml",
                    "coverage_report": {
                        "coverage_format": "cobertura",
                        "path": "coverage.xml",
                    }
                },
                "paths": ["htmlcov/"],
                "expire_in": "1 week",
            },
        }
    elif project_type == "go":
        jobs["test:unit"] = {
            "stage": "test",
            "script": [
                "go test -v -race -coverprofile=coverage.out ./...",
                "go tool cover -html=coverage.out -o coverage.html",
            ],
            "coverage": "/coverage: \\d+\\.\\d+% of statements/",
            "artifacts": {
                "paths": ["coverage.html", "coverage.out"],
                "expire_in": "1 week",
            },
        }

    return jobs


def _generate_build_jobs(project_type: str, package_manager: str, docker_enabled: bool) -> Dict[str, Any]:
    """Generate build stage jobs."""
    jobs = {}

    if project_type in ["node", "nextjs", "react", "vue"]:
        run_cmd = "npm run" if package_manager == "npm" else f"{package_manager} run"
        jobs["build:app"] = {
            "stage": "build",
            "script": [f"{run_cmd} build"],
            "artifacts": {
                "paths": [".next/", "dist/", "build/", "out/"],
                "expire_in": "1 day",
            },
        }

    if docker_enabled:
        jobs["build:docker"] = {
            "stage": "build",
            "image": "docker:24.0.5",
            "services": ["docker:24.0.5-dind"],
            "script": [
                'docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .',
                'docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA $CI_REGISTRY_IMAGE:latest',
                'echo "$CI_REGISTRY_PASSWORD" | docker login -u "$CI_REGISTRY_USER" --password-stdin $CI_REGISTRY',
                'docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA',
                'docker push $CI_REGISTRY_IMAGE:latest',
            ],
            "rules": [
                {"if": '$CI_COMMIT_BRANCH == "main"'},
                {"if": '$CI_COMMIT_TAG'},
            ],
        }

    return jobs


def _generate_security_jobs(project_type: str) -> Dict[str, Any]:
    """Generate security stage jobs."""
    jobs = {
        "sast": {
            "stage": "security",
            "image": "returntocorp/semgrep",
            "script": ["semgrep scan --config auto --json --output semgrep.json ."],
            "artifacts": {
                "reports": {"sast": "semgrep.json"},
                "paths": ["semgrep.json"],
            },
            "allow_failure": True,
        },
        "dependency_scan": {
            "stage": "security",
            "script": [],
            "allow_failure": True,
        },
        "secret_detection": {
            "stage": "security",
            "image": "trufflesecurity/trufflehog:latest",
            "script": ["trufflehog git file://. --json > secrets.json || true"],
            "artifacts": {
                "paths": ["secrets.json"],
            },
            "allow_failure": True,
        },
    }

    # Add language-specific dependency scanning
    if project_type in ["node", "nextjs", "react", "vue", "express", "nestjs"]:
        jobs["dependency_scan"]["image"] = "node:20-alpine"
        jobs["dependency_scan"]["script"] = [
            "npm audit --json > npm-audit.json || true",
        ]
    elif project_type == "python":
        jobs["dependency_scan"]["image"] = "python:3.11-slim"
        jobs["dependency_scan"]["script"] = [
            "pip install safety pip-audit",
            "safety check --json > safety.json || true",
            "pip-audit --format json > pip-audit.json || true",
        ]

    return jobs


def _generate_deploy_jobs(project_type: str, environments: List[str]) -> Dict[str, Any]:
    """Generate deploy stage jobs."""
    jobs = {}

    for env in environments:
        job_name = f"deploy:{env}"
        jobs[job_name] = {
            "stage": "deploy",
            "environment": {
                "name": env,
                "url": f"https://{env}.example.com",
            },
            "script": [
                f'echo "Deploying to {env}..."',
                'kubectl set image deployment/$APP_NAME $APP_NAME=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA',
                'kubectl rollout status deployment/$APP_NAME',
            ],
        }

        # Add rules based on environment
        if env == "production":
            jobs[job_name]["rules"] = [
                {"if": '$CI_COMMIT_BRANCH == "main"', "when": "manual"},
            ]
            jobs[job_name]["when"] = "manual"
        elif env == "staging":
            jobs[job_name]["rules"] = [
                {"if": '$CI_COMMIT_BRANCH == "main"'},
            ]
        else:  # development
            jobs[job_name]["rules"] = [
                {"if": '$CI_COMMIT_BRANCH'},
            ]

    return jobs


def _format_jobs_summary(jobs: Dict[str, Any]) -> str:
    """Format jobs summary for output."""
    lines = []
    for name, config in jobs.items():
        stage = config.get("stage", "unknown")
        lines.append(f"- **{name}** (stage: {stage})")
    return "\n".join(lines)


def _format_env_table(environments: List[Dict[str, Any]]) -> str:
    """Format environment table."""
    lines = []
    for env in environments:
        name = env.get("name", "unknown")
        auto = "Yes" if env.get("auto_deploy", False) else "No"
        approval = "Yes" if env.get("requires_approval", False) else "No"
        branch = "main" if name in ["staging", "production"] else "*"
        lines.append(f"| {name} | {auto} | {approval} | {branch} |")
    return "\n".join(lines)


def _generate_custom_job(job_name: str, stage_name: str, config: Dict[str, Any]) -> str:
    """Generate YAML for a custom job."""
    job = {
        "stage": stage_name,
        "script": config.get("script", ["echo 'No script defined'"]),
    }

    if "image" in config:
        job["image"] = config["image"]
    if "variables" in config:
        job["variables"] = config["variables"]
    if "artifacts" in config:
        job["artifacts"] = config["artifacts"]
    if "rules" in config:
        job["rules"] = config["rules"]

    return _dict_to_gitlab_yaml({job_name: job})


def _generate_docker_runner_config(concurrent: int, tags: List[str], image: str) -> str:
    """Generate Docker runner config.toml."""
    return f'''concurrent = {concurrent}
check_interval = 0
shutdown_timeout = 0

[session_server]
  session_timeout = 1800

[[runners]]
  name = "NAVI Docker Runner"
  url = "https://gitlab.com/"
  token = "YOUR_RUNNER_TOKEN"
  executor = "docker"
  [runners.custom_build_dir]
  [runners.cache]
    MaxUploadedArchiveSize = 0
    [runners.cache.s3]
    [runners.cache.gcs]
    [runners.cache.azure]
  [runners.docker]
    tls_verify = false
    image = "{image}"
    privileged = true
    disable_entrypoint_overwrite = false
    oom_kill_disable = false
    disable_cache = false
    volumes = ["/cache", "/certs/client"]
    shm_size = 0
'''


def _generate_k8s_runner_config(concurrent: int, tags: List[str]) -> str:
    """Generate Kubernetes runner config.toml."""
    return f'''concurrent = {concurrent}
check_interval = 0

[[runners]]
  name = "NAVI Kubernetes Runner"
  url = "https://gitlab.com/"
  token = "YOUR_RUNNER_TOKEN"
  executor = "kubernetes"
  [runners.kubernetes]
    host = ""
    bearer_token_overwrite_allowed = false
    image = "alpine:latest"
    namespace = "gitlab-runner"
    namespace_overwrite_allowed = ""
    privileged = true
    service_account = "gitlab-runner"
    pull_policy = ["if-not-present"]
    [runners.kubernetes.affinity]
    [runners.kubernetes.pod_security_context]
    [runners.kubernetes.volumes]
'''


def _generate_shell_runner_config(concurrent: int, tags: List[str]) -> str:
    """Generate Shell runner config.toml."""
    return f'''concurrent = {concurrent}
check_interval = 0

[[runners]]
  name = "NAVI Shell Runner"
  url = "https://gitlab.com/"
  token = "YOUR_RUNNER_TOKEN"
  executor = "shell"
  shell = "bash"
  [runners.custom_build_dir]
  [runners.cache]
    MaxUploadedArchiveSize = 0
'''


def _generate_cd_config(environments: List[Dict], strategy: str, project_info: Dict) -> Dict:
    """Generate CD configuration."""
    config = {
        "stages": ["deploy"],
        "variables": {
            "DEPLOYMENT_STRATEGY": strategy,
        },
    }

    for env in environments:
        env_name = env.get("name", "unknown")
        job_name = f"deploy_{env_name}"

        config[job_name] = {
            "stage": "deploy",
            "environment": {
                "name": env_name,
                "url": f"https://{env_name}.example.com",
            },
            "script": _get_deploy_script(strategy, env_name),
        }

        if env.get("requires_approval", False):
            config[job_name]["when"] = "manual"

        if not env.get("auto_deploy", True):
            config[job_name]["rules"] = [
                {"if": '$CI_COMMIT_BRANCH == "main"', "when": "manual"}
            ]

    return config


def _get_deploy_script(strategy: str, environment: str) -> List[str]:
    """Get deployment script based on strategy."""
    if strategy == "blue_green":
        return [
            f'echo "Blue-Green deployment to {environment}"',
            'kubectl apply -f k8s/green/',
            'kubectl wait --for=condition=ready pod -l version=green --timeout=300s',
            'kubectl patch service $SERVICE -p \'{"spec":{"selector":{"version":"green"}}}\'',
            'kubectl delete -f k8s/blue/ || true',
        ]
    elif strategy == "canary":
        return [
            f'echo "Canary deployment to {environment}"',
            'kubectl apply -f k8s/canary/',
            'sleep 300',
            'kubectl scale deployment canary --replicas=0',
            'kubectl apply -f k8s/production/',
        ]
    else:  # rolling
        return [
            f'echo "Rolling deployment to {environment}"',
            'kubectl set image deployment/$APP_NAME $APP_NAME=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA',
            'kubectl rollout status deployment/$APP_NAME --timeout=300s',
        ]


def _generate_docker_template() -> str:
    """Generate Docker CI template."""
    return '''.docker:build:
  stage: build
  image: docker:24.0.5
  services:
    - docker:24.0.5-dind
  variables:
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: "/certs"
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .
    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA

.docker:deploy:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl set image deployment/$APP_NAME $APP_NAME=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
    - kubectl rollout status deployment/$APP_NAME
'''


def _generate_node_template() -> str:
    """Generate Node.js CI template."""
    return '''.node:install:
  image: node:20-alpine
  cache:
    key: ${CI_COMMIT_REF_SLUG}-node
    paths:
      - node_modules/
      - .npm/
  before_script:
    - npm ci --prefer-offline

.node:lint:
  extends: .node:install
  stage: lint
  script:
    - npm run lint
    - npm run format:check

.node:test:
  extends: .node:install
  stage: test
  script:
    - npm run test -- --coverage
  coverage: /All files[^|]*\\|[^|]*\\s+([\\d\\.]+)/
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage/cobertura-coverage.xml

.node:build:
  extends: .node:install
  stage: build
  script:
    - npm run build
  artifacts:
    paths:
      - dist/
      - .next/
    expire_in: 1 day
'''


def _generate_python_template() -> str:
    """Generate Python CI template."""
    return '''.python:install:
  image: python:3.11-slim
  variables:
    PIP_CACHE_DIR: "$CI_PROJECT_DIR/.pip-cache"
  cache:
    key: ${CI_COMMIT_REF_SLUG}-python
    paths:
      - .pip-cache/
      - .venv/
  before_script:
    - python -m venv .venv
    - source .venv/bin/activate
    - pip install --upgrade pip
    - pip install -r requirements.txt

.python:lint:
  extends: .python:install
  stage: lint
  script:
    - pip install ruff black mypy
    - ruff check .
    - black --check .
    - mypy .

.python:test:
  extends: .python:install
  stage: test
  script:
    - pip install pytest pytest-cov pytest-asyncio
    - pytest --cov=. --cov-report=xml --junitxml=junit.xml
  coverage: /TOTAL.*\\s+(\\d+%)$/
  artifacts:
    reports:
      junit: junit.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
'''


def _generate_terraform_template() -> str:
    """Generate Terraform CI template."""
    return '''.terraform:base:
  image: hashicorp/terraform:1.6
  cache:
    key: ${CI_COMMIT_REF_SLUG}-terraform
    paths:
      - .terraform/

.terraform:validate:
  extends: .terraform:base
  stage: lint
  script:
    - terraform init -backend=false
    - terraform validate
    - terraform fmt -check -recursive

.terraform:plan:
  extends: .terraform:base
  stage: build
  script:
    - terraform init
    - terraform plan -out=tfplan
  artifacts:
    paths:
      - tfplan
    expire_in: 1 day

.terraform:apply:
  extends: .terraform:base
  stage: deploy
  script:
    - terraform init
    - terraform apply -auto-approve tfplan
  when: manual
  dependencies:
    - terraform:plan
'''


def _generate_security_template() -> str:
    """Generate Security scanning CI template."""
    return '''.security:sast:
  stage: security
  image: returntocorp/semgrep
  script:
    - semgrep scan --config auto --json --output semgrep.json .
  artifacts:
    reports:
      sast: semgrep.json
  allow_failure: true

.security:secrets:
  stage: security
  image: trufflesecurity/trufflehog:latest
  script:
    - trufflehog git file://. --json > secrets.json
  artifacts:
    paths:
      - secrets.json
  allow_failure: true

.security:container:
  stage: security
  image: aquasec/trivy:latest
  script:
    - trivy image --format json --output trivy.json $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
  artifacts:
    paths:
      - trivy.json
  allow_failure: true
'''


def _dict_to_gitlab_yaml(data: Dict[str, Any], indent: int = 0) -> str:
    """Convert dictionary to YAML string (simple implementation)."""
    lines = []
    prefix = "  " * indent

    for key, value in data.items():
        if isinstance(value, dict):
            lines.append(f"{prefix}{key}:")
            lines.append(_dict_to_gitlab_yaml(value, indent + 1))
        elif isinstance(value, list):
            lines.append(f"{prefix}{key}:")
            for item in value:
                if isinstance(item, dict):
                    # First key on same line as dash
                    first = True
                    for k, v in item.items():
                        if first:
                            if isinstance(v, dict):
                                lines.append(f"{prefix}  - {k}:")
                                lines.append(_dict_to_gitlab_yaml(v, indent + 3))
                            else:
                                lines.append(f"{prefix}  - {k}: {_format_value(v)}")
                            first = False
                        else:
                            if isinstance(v, dict):
                                lines.append(f"{prefix}    {k}:")
                                lines.append(_dict_to_gitlab_yaml(v, indent + 3))
                            else:
                                lines.append(f"{prefix}    {k}: {_format_value(v)}")
                else:
                    lines.append(f"{prefix}  - {_format_value(item)}")
        else:
            lines.append(f"{prefix}{key}: {_format_value(value)}")

    return "\n".join(lines)


def _format_value(value: Any) -> str:
    """Format a value for YAML output."""
    if isinstance(value, bool):
        return "true" if value else "false"
    elif isinstance(value, str):
        # Quote strings with special characters
        if any(c in value for c in [':', '#', '{', '}', '[', ']', ',', '&', '*', '?', '|', '-', '<', '>', '=', '!', '%', '@', '`']):
            return f'"{value}"'
        elif value == "":
            return '""'
        return value
    elif value is None:
        return "null"
    else:
        return str(value)


# ============================================================================
# Tool Registry
# ============================================================================

GITLAB_CI_TOOLS = {
    "gitlab_ci_generate": generate_gitlab_ci,
    "gitlab_ci_add_stage": add_gitlab_ci_stage,
    "gitlab_ci_setup_runners": setup_gitlab_runners,
    "gitlab_ci_generate_cd": generate_gitlab_cd,
    "gitlab_ci_generate_templates": generate_gitlab_templates,
}
